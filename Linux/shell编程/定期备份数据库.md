# 定期备份数据库

### 一、要求
1. 对备份文件进行打包，并传到备份目录
2. 如果备份目录的文件达到10个，删除最早的备份文件
3. 每两分钟执行一次。

### 二、方案
1. 使用 `mysqldump` 进行备份
2. 使用 `crontab` 设置定期执行 
3. 步骤
    - 使用 `mysqldump` 备份数据库后，通过 `tar` 指令压缩文件并复制到备份目录。 
    - 判断 `/home/backup` 目录里面的文件数量
        - 文件数量等于11个时，删除最早的文件
        - 否则不给予处理
    - 在任务计划里面设置定期执行，每两分钟备份一次。

### 三 、具体实现

1. 先在`backup.sh` 代码实现备份功能
   - 变量命名采用位置参数变量，可以比较灵活的更改备份资源。在crontab任务计划里面设置参数
   - 使用 `awk` 相关指令获取展示列表的某几行、某几列以及行数。`awk`指令用来进行文本处理，通过空格来对每个列进行区分。
      - `$0`获取整行的字段，`$1`获取第1列的字段，依次类推。
      - `NR` 指定行数。
      - `'匹配规则{执行语句}'` 用来对匹配的文本进行处理。

```
    PWD=$2
    HOST=$3
    DATETIME=$(date +%Y-%m-%d_%H%M%S)
    #DB_BACK_PATH=/home/backup/
    DB_BACK_PATH=$4
    DATABASE=$5
    DB_PATH=${DB_BACK_PATH}/${DATETIME}/
    #判断目录是否存在，如果不存在，则创建该目录
    [ ! -d ${DB_PATH} ] && mkdir -p  ${DB_PATH}
    #避免手动录入密码，需要把选项跟变量拼接。
    mysqldump -u${NAME} -p${PWD} -h${HOST} --databases ${DATABASE} | gzip -rq > ${DB_PATH}/${DATETIME}.sql.gz

    #切换到备份目录里，对整个目录进行打包压缩，然后删除掉源文件
    cd ${DB_BACK_PATH}
    tar -zvcf ${DATETIME}.tar.gz ${DATETIME}/ --remove-files
    
    #获取压缩包的总数，如果超过10个就删除掉最早的。
    LEN=$(ls -lrt | awk 'END{print NR}')

    if [ $[$LEN - 1] -gt 10 ]
    then
            FILENAME=$(ls -lrt | awk 'NR==2{print}' | awk '{print $9}')
            find / -name ${FILENAME} -exec rm -rf {} +
    fi
```

2. 编写任务计划
  - 创建任务计划，并录入以下内容。
```
    */2 * * * * /home/shellDemo/backup.sh root root localhost /home/backup chat      
```
  - 使用 `crontab -l` 指令复制到执行目录执行。
    